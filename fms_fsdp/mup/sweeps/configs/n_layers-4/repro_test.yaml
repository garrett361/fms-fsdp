# Test two sweeps with an irrelevant param change.
name: repro-test
method: grid
metric:
  goal: minimize
  name: loss
parameters:
  file_type:
    value: auto
  col_name:
    value: contents
  tokenizer_path:
    value: /datasets/tokenizers/llama3
  weights:
    value: 1
  vocab_size:
    value: 128256
  bos_token:
    value: null
  eos_token:
    value: 128000
  use_torch_compile:
    value: False
  data_path:
    value: /datasets/dolma_v1_7
  datasets:
    value: dataset=cc_en_head
  tracker:
    value: wandb
  n_layer:
    value: 4
  head_dim:
    value: 128
  d_model:
    values:
      - 512
  # 2**20 tok batch size: seq_len = 4096 = 2**12, batch_size * acc_steps = 256 = 2**8
  seq_length:
    value: 4096
  batch_size:
    value: 4
  acc_steps:
    value: 64
  num_steps:
    value: 1024
  report_interval:
    value: 64
  mup:
    value: false
  # mup_emb_scale not actually used
  mup_emb_scale:
    values:
      - 0
      - 1
  # LRs: log-spaced between 1e-3 and 1e-5, inclusive. [f"{10**(-n/3):.3e}" for n in range(9, 16)]
  learning_rate:
    values:
    - 1.000e-03
    - 4.642e-04
    - 2.154e-04
    - 1.000e-04
    - 4.642e-05
    - 2.154e-05
    - 1.000e-05
