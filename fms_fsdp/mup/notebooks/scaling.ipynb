{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511b5a01-d18b-4a8a-b7dd-710a86479032",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mamba_ssm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mamba_ssm'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import mamba_ssm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec0639-0b44-4373-ab28-adf866db1eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features_min=64\n",
    "in_features_max=8192\n",
    "head_dim=64\n",
    "seq_len=512\n",
    "bsz=2\n",
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d174e-a4a8-40c9-b1ab-4be42fa8181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feat = in_features_min\n",
    "in_features_list = []\n",
    "while in_feat <= in_features_max:\n",
    "    in_features_list.append(in_feat)\n",
    "    in_feat *= 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5b9316-f9a7-479e-9afe-7d112dcbb80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lins(mod: nn.Module)->None:\n",
    "    for lin_name, lin in mod.named_modules():\n",
    "        if isinstance(lin, nn.Linear):\n",
    "            print(f\"Init {lin_name=}\")\n",
    "            nn.init.normal_(lin.weight, std=1/(lin.in_features**0.5))\n",
    "            if lin.bias is not None:\n",
    "                nn.init.zeros_(lin.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f747fd-3e5e-4e08-a584-e6b9197e5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = GatedMLP(512, device=device)\n",
    "with torch.no_grad():\n",
    "    print(mlp.fc1.weight.mean())\n",
    "    print(mlp.fc1.weight.pow(2).mean())\n",
    "\n",
    "mlp = GatedMLP(512, device=device)\n",
    "init_lins(mlp)\n",
    "with torch.no_grad():\n",
    "    print(mlp.fc1.weight.mean())\n",
    "    print(mlp.fc1.weight.pow(2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9cfa5-0f07-48ff-a8de-b7063984d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(16, 512, device=device)\n",
    "lin = nn.Linear(512, 512, bias=False, device=device)\n",
    "with torch.no_grad():\n",
    "    out = lin(inputs)\n",
    "    print(out.mean())\n",
    "    print(out.pow(2).mean())\n",
    "    \n",
    "lin = nn.Linear(512, 512, bias=False, device=device)\n",
    "init_lins(lin)\n",
    "with torch.no_grad():\n",
    "    out = lin(inputs)\n",
    "    print(out.mean())\n",
    "    print(out.pow(2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acecc6bc-134b-4738-a5eb-a9e9f5ec32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mamba_ssm.modules.mlp import GatedMLP\n",
    "    \n",
    "mlp_amp = False\n",
    "mlp_results = []\n",
    "for custom_init in (True, False):\n",
    "    for in_features in tqdm(in_features_list): \n",
    "        mlp = GatedMLP(in_features, device=device)\n",
    "        if custom_init:\n",
    "            init_lins(mlp)\n",
    "        \n",
    "        inputs = torch.randn(bsz, seq_len, in_features, device=device)\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16, enabled=mlp_amp):\n",
    "                outputs = mlp(inputs)\n",
    "        mlp_results_dict = {\"in_features\": in_features,\n",
    "                        \"l2_mean\": outputs.pow(2).mean().item(),\n",
    "                        \"l1_mean\": outputs.abs().mean().item(),\n",
    "                        \"l2_sum\": outputs.pow(2).sum().item(),\n",
    "                        \"l1_sum\": outputs.abs().sum().item(),\n",
    "                        \"std\": outputs.std().item(),\n",
    "                        \"var\": outputs.var().item(),\n",
    "                        \"mean\": outputs.mean().item(),\n",
    "                        \"custom_init\": custom_init,\n",
    "                       }\n",
    "        mlp_results.append(mlp_results_dict)\n",
    "    \n",
    "mlp_df = pd.DataFrame(mlp_results)\n",
    "mlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65101241-9c8d-4e8d-af68-34bc172eefc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_plot = sns.lineplot(data=mlp_df, x=\"in_features\", y=\"l2_mean\", hue=\"custom_init\")\n",
    "mlp_plot.set(xscale=\"log\")\n",
    "mlp_plot.set(yscale=\"log\")\n",
    "plt.suptitle(\"MLP scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60022215-6657-4100-95b2-f4f40895d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mamba_ssm.modules.mha import MHA\n",
    "\n",
    "attn_results = []\n",
    "attn_amp = False\n",
    "for custom_init in (True, False):\n",
    "    for in_features in tqdm(in_features_list):\n",
    "        attn_cfg = {\n",
    "        \"causal\": True,\n",
    "        \"head_dim\": head_dim,\n",
    "        \"num_heads\": in_features // head_dim,\n",
    "        \"out_proj_bias\": False,\n",
    "        \"qkv_proj_bias\": False,\n",
    "        \"rotary_emb_dim\": head_dim // 2,  # Apparently correct for mamba-ssm\n",
    "    }\n",
    "    \n",
    "        mha = MHA(in_features, **attn_cfg, device=device)\n",
    "        if custom_init:\n",
    "            init_lins(mha)\n",
    "        inputs = torch.randn(bsz, seq_len, in_features, device=device)\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16, enabled=attn_amp):\n",
    "                outputs = mha(inputs)\n",
    "        attn_results_dict = {\"in_features\": in_features,\n",
    "                        \"l2_mean\": outputs.pow(2).mean().item(),\n",
    "                        \"l1_mean\": outputs.abs().mean().item(),\n",
    "                        \"l2_sum\": outputs.pow(2).sum().item(),\n",
    "                        \"l1_sum\": outputs.abs().sum().item(),\n",
    "                        \"std\": outputs.std().item(),\n",
    "                        \"var\": outputs.var().item(),\n",
    "                        \"mean\": outputs.mean().item(),\n",
    "                        \"custom_init\": custom_init,\n",
    "                       }\n",
    "        attn_results.append(attn_results_dict)\n",
    "\n",
    "attn_df = pd.DataFrame(attn_results)\n",
    "attn_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7796d-dd81-421f-adf3-a98361fcf910",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_plot = sns.lineplot(data=attn_df, x=\"in_features\", y=\"l2_mean\", hue=\"custom_init\")\n",
    "attn_plot.set(xscale=\"log\")\n",
    "attn_plot.set(yscale=\"log\")\n",
    "\n",
    "plt.suptitle(\"MHA scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2851a398-62e7-4d1a-9b65-5694e6b7110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from typing import Any, Optional\n",
    "\n",
    "class InputStatsHook:\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: nn.Module,\n",
    "        name: str,\n",
    "        results_list: list[dict],\n",
    "        width: int,\n",
    "        other_data: Optional[dict] = None,\n",
    "    ) -> None:\n",
    "        self.module = module\n",
    "        self.name = name\n",
    "        self.width = width\n",
    "        self.results_list = results_list\n",
    "        self._hook = module.register_forward_pre_hook(self)\n",
    "        self._step = 0\n",
    "        self.other_data = other_data or {}\n",
    "\n",
    "    def __call__(self, module: nn.Module, args: Any) -> None:\n",
    "        inputs = args[0]\n",
    "        results = {\"name\": self.name, \"width\": self.width, \"step\": self._step}\n",
    "        results = {**results, **self.other_data}\n",
    "        with torch.no_grad():\n",
    "            results[\"mean\"] = inputs.mean().item()\n",
    "            results[\"l1_mean\"] = inputs.abs().mean().item()\n",
    "            results[\"l2_mean\"] = inputs.pow(2).mean().item()\n",
    "            results[\"std\"] = inputs.std().item()\n",
    "            results[\"var\"] = inputs.var().item()\n",
    "        self.results_list.append(results)\n",
    "        self._step += 1\n",
    "\n",
    "\n",
    "\n",
    "    def remove(self) -> None:\n",
    "        self._hook.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325fc370-f870-4e29-af18-4a3cd052f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mamba_ssm.models.config_mamba import MambaConfig\n",
    "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\n",
    "from fms_fsdp.mup.mup_mamba import apply_mup_init\n",
    "\n",
    "\n",
    "model_results = []\n",
    "lm_head_input_results = []\n",
    "model_amp = True\n",
    "mup = True\n",
    "n_layer=4\n",
    "vocab_size=128256\n",
    "head_dim=128\n",
    "for in_features in trange(in_features_min, in_features_max+1, 4*head_dim):\n",
    "    attn_cfg = {\n",
    "    \"causal\": True,\n",
    "    \"head_dim\": head_dim,\n",
    "    \"num_heads\": in_features // head_dim,\n",
    "    \"out_proj_bias\": False,\n",
    "    \"qkv_proj_bias\": False,\n",
    "    \"rotary_emb_dim\": head_dim // 2,  # Apparently correct for mamba-ssm\n",
    "}\n",
    "    if mup:\n",
    "        attn_cfg[\"softmax_scale\"] = head_dim\n",
    "    \n",
    "    config = MambaConfig(\n",
    "    d_model=in_features,\n",
    "    d_intermediate=4 * in_features,\n",
    "    n_layer=n_layer,\n",
    "    attn_layer_idx=list(range(n_layer)),  # Transformer-only blocks\n",
    "    vocab_size=vocab_size,\n",
    "    attn_cfg=attn_cfg,\n",
    "    tie_embeddings=False,\n",
    ")\n",
    "    model = MambaLMHeadModel(config=config, device=device)\n",
    "\n",
    "    hook = InputStatsHook(model.lm_head, \"lm_head\", lm_head_input_results, width=in_features)\n",
    "    if mup:\n",
    "        apply_mup_init(model)\n",
    "    inputs = torch.randint(vocab_size, size=(bsz, seq_len), device=device)\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16, enabled=model_amp):\n",
    "            outputs = model(inputs).logits\n",
    "        print(f\"{outputs.shape=}, {in_features=}\")\n",
    "    model_results_dict = {\"in_features\": in_features,\n",
    "                    \"l2_mean\": outputs.pow(2).mean().item(),\n",
    "                    \"l1_mean\": outputs.abs().mean().item(),\n",
    "                    \"l2_sum\": outputs.pow(2).sum().item(),\n",
    "                    \"l1_sum\": outputs.abs().sum().item(),\n",
    "                    \"std\": outputs.std().item(),\n",
    "                    \"var\": outputs.var().item(),\n",
    "                    \"mean\": outputs.mean().item(),\n",
    "                   }\n",
    "    model_results.append(model_results_dict)\n",
    "model_df = pd.DataFrame(model_results)\n",
    "model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf832a35-f83c-400b-97db-20d747ca6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plot = sns.lineplot(data=model_df, x=\"in_features\", y=\"l2_mean\")\n",
    "model_plot.set(xscale=\"log\")\n",
    "model_plot.set(yscale=\"log\")\n",
    "\n",
    "plt.suptitle(\"Model scaling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9259650-3197-4453-a395-8d9b7c06c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_head_df = pd.DataFrame(lm_head_input_results)\n",
    "lm_head_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87609d11-8354-4c1d-89f1-9c53fb822b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_head_plot = sns.lineplot(data=lm_head_df, x=\"width\", y=\"l2_mean\")\n",
    "lm_head_plot.set(xscale=\"log\")\n",
    "lm_head_plot.set(yscale=\"log\")\n",
    "\n",
    "plt.suptitle(\"LM Head scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d97a59-8fef-4a58-b5d1-928972ec94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_head_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d159c8-4d3f-4e7e-bfd4-a2de832ca2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [{\"x\": y, \"y\":y + 1 if group == \"red\" else 0, \"group\": group} for group in (\"red\", \"blue\") for y in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f445eef-79a4-412c-892f-188494b6067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_data)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210ec1b-c9a2-4677-80c6-2c0a3fb4334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=test_df, x=\"x\", y=\"y\", hue=\"group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e736f7-1daf-4745-b472-368f6b10469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {g: (1, 0) for g in test_df.group.unique()}\n",
    "dd[\"blue\"] = (4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b88ce27-dd56-49e1-ad51-ae06ae1ae67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=test_df, x=\"x\", y=\"y\", hue=\"group\", dashes=dd, style=\"group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ead2d2-b73b-448a-b297-ab921011fdda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
