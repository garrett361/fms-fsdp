name: 4-layer-sweep-long-wide-large-lrs
method: grid
metric:
  goal: minimize
  name: loss
parameters:
  file_type:
    value: auto
  col_name:
    value: contents
  tokenizer_path:
    value: /datasets/tokenizers/llama3
  weights:
    value: 1
  vocab_size:
    value: 128256
  bos_token:
    value: null
  eos_token:
    value: 128000
  use_torch_compile:
    value: False
  data_path:
    value: /datasets/dolma_v1_7
  datasets:
    value: dataset=cc_en_head
  tracker:
    value: wandb
  n_layer:
    value: 4
  head_dim:
    value: 128
  d_model:
    values:
      - 256
      - 512
      - 1024
      - 2048
      - 4096
      - 8196
      - 16392
  optim:
    value: adamw
  mup_base_d_model:
    value: 256
  seq_length:
    value: 512
  batch_size:
    value: 8
  acc_steps:
    value: 1
  world_size:
    value: 8
  num_steps:
    value: 8192
  report_interval:
    value: 64
  mup:
    values:
    - true
    - false
  mup_simple_scaling_impl:
    value: false
  # LRs: log-spaced
  learning_rate:
    values:
      - 0.1
      - 0.05623413251903491
      - 0.031622776601683794
      - 0.017782794100389228
